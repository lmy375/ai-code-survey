# AI Code Survey

This repository uses an MCP Server development project as an example to test the practical performance of various AI Coders, including:

- Remote Agent
    - [Augment Code](https://github.com/lmy375/shell-mcp-augment-code)
    - [Codex](https://github.com/lmy375/shell-mcp-codex)
    - [Google Jules](https://github.com/lmy375/shell-mcp-jules)
- Local Agent
    - [Claude Code](./claude-code-sonnet-4/)
    - [Codex cli](./codex-cli-auto/)
    - [Cursor](./cursor-auto/)
    - [Github Copilot](./github-copilot-gpt41/)
    - [Augment Code](./augment-code/)
    - [Cline](./cline-opus-4/)

The full evaluation can be found [here](./blog/blog.md).

Test prompts are available [here](./prompt.txt).

The complete AI interaction logs are in the txt or md files under each subdirectory.
